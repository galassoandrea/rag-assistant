# ü§ñ FinSearchAI: a RAG Assistant for Financial Insights

## üìñ Overview

FinSearch AI is a specialized Retrieval-Augmented Generation (RAG) system designed to answer financial queries using professional-grade open-source models. While standard RAG systems often struggle with the "noise" and structural complexity of financial data, this project implements a custom data-engineering pipeline to ensure high-fidelity retrieval and reasoning.

The system currently achieves an accuracy rate of about 70% in providing context-aware answers derived from 10-K filings of different companies.

## üìú Steps

The RAG assistant works in a series of steps:

1. Download the 10-K filings for the choosen companies.
   
3. Preprocess the documents, split them into overlapping chunks based on HTML elements, extract metadata, generate document embeddings and store them on a vector store.
   
4. After formulating a financial query, embed it, retrieve the most relevant documents w.r.t. the query and pass them as context to an LLM, to generate the final answer.

Entering more into the details, the retrieval step consists in the following pipeline:

1. Hybrid (Ensemble) Retrieval: the search for relevant documents is performed both semantically (vector search) and syntacticaly (document search). These 2 processes, produce separate scores for the set of documents, which are then combined and used to find the top 20 documents.

2. Reranking: The 20 most relevant documents extracted by the previous step are reranked using a CrossEncoder, by computing a final relevance score for each couple query-document and the top 5 documents are returned and used to generate the answer to the query.

## üõ†Ô∏è Technical Details

- To develop the system, pure python is used (along with the APIs of the needed services). In a previous version of the project I was using the langchain framework but, since its recent updates were breaking everything, I decided to switch to pure python for better stability.

- The 10-K filings used for the system are about 2 companies: Apple (APPL) and Nvidia (NVDA). I plan to include the data also for other 3 companies (Mircrosoft, Tesla and Google) in the next update.
  
- For the Hybrid Retrieval pipeline, the model used to generate the documents' embeddings is BAAI/bge-m3, via Hugging Face Inference Endpoints, while BM25 is used for document search.

- The CrossEncoder used for reranking is BAAI/bge-reranker-v2-m3, which belongs to the same family of the embedding model.

- The brain (LLM) used for answering the queries is llama-3.3-70b-versatile, via the Groq API.
  
- To store the documents embeddings and perform high-speed semantic search, Pinecone (Cloud Vector DB) has been used.

## üîé Usage instructions

I plan to host the application using an appropriate service soon. In the meantime, you can test it locally in the following way:

### Clone the repository 

```sh 
git clone https://github.com/galassoandrea/rag-assistant.git
```

### Get you API keys for Groq and Pinecone

Store them in a .env file and create a Pinecone index (you can do it through the UI).

### Install dependencies

```sh 
pip install -r requirements.txt
```

### Automatically download the 10-K filings

 You need to set a valid email address inside the script.

```sh 
python scripts/download_data.py
```

### Run the ingestion script

Create the document embeddings and store them in your Pinecone index.

```sh 
python scripts/ingest.py
```

### Launch the application

You will be redirected to a generated chainlit UI, which will allow you to interact with the system.

```sh 
chainlit run app.py -w
```

To test the system, you can use the following queries, grouped by complexity level, which have been generated by Gemini 3 Pro, by passing to it the original documents, let it analyze them carefully and finally generate the queries.
The queries have been also validated by me, to confirm that the information required by each of them, is contained inside the original documents.

### Level 1: Basic Retrieval

These queries test the system‚Äôs ability to find specific data points and terminology within a single document.

- What was NVIDIA's total revenue for fiscal year 2025?

- List the primary reportable segments Apple uses for its business.

- What are NVIDIA‚Äôs "inventory purchase obligations in excess of projections" as of the end of fiscal 2025?

- What specific legal investigation regarding "EU State Aid Rules" is mentioned in Apple‚Äôs 10-K?

### Level 2: Summarization & Synthesis

These queries require the system to aggregate information from different sections of the same document.

- Summarize the performance differences between the "Compute and Networking" and "Graphics" segments for NVIDIA in fiscal 2025.

- Based on the revenue data, which product line is Apple's largest, and what percentage of total net sales does it represent for 2025?

- What are the top three supply chain risks identified by NVIDIA management in the most recent filing?

- Describe Apple's debt issuance activity during fiscal year 2025, specifically mentioning fixed-rate notes.

### Level 3: Comparative Analysis

These queries test the system‚Äôs ability to retrieve information from both files and perform a meaningful comparison.

- Compare the total research and development (R&D) expenses for Apple and NVIDIA in their respective 2025 fiscal years.

- Contrast the geographic revenue distribution of NVIDIA (e.g., Singapore vs. US) with Apple‚Äôs regional segments (e.g., Greater China vs. Americas).

- Explain the difference between the end dates of the 2025 fiscal years for NVIDIA and Apple.

- How do both companies describe the risks associated with the development and deployment of artificial intelligence (AI) in their business models?

### Level 4: Complex Reasoning & Financial Logic

These queries require the system to perform calculations or interpret vague language into concrete financial insights.

- Based on the "Income Tax" notes in both filings, which company appears to be more affected by foreign jurisdiction tax rates, and why?

- Calculate the operating margin (Operating Income / Total Revenue) for both companies and explain which company operated more efficiently in 2025 based on this metric.

- Compare how Apple and NVIDIA handle "Loss Contingencies" related to class action lawsuits or derivative lawsuits as of the filing dates.
